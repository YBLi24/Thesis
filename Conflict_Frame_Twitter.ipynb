{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Q9cTX6o88Mi8pqGdT4_T3PZaLSIEdrDO",
      "authorship_tag": "ABX9TyP6EMjChDv80lFB3btf58nj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YBLi24/Thesis/blob/main/Conflict_Frame_Twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqdsjL4rnI_Z",
        "outputId": "dd372870-a74b-4b84-b4f3-8071ecf24656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 18 01:58:16 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    52W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers"
      ],
      "metadata": {
        "id": "0QGbBFC0mt_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YTVMp8JmeXC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (\"/content/drive/MyDrive/【Thesis】/twitter_500_preprocessed.csv\")\n",
        "labels = {0:0, 1:1, 2:1, 3:1, 4:1}\n",
        "df[\"cf_binary\"]=[labels[label]for label in df[\"Conflict frames\"]]\n",
        "df"
      ],
      "metadata": {
        "id": "wx9W47aNmyAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = np.split(df.sample(frac=1, random_state=42), [int(.6*len(df))])\n",
        "print(len(df_train), len(df_val))"
      ],
      "metadata": {
        "id": "WM011EqzmzHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextLabelDataset(Dataset):\n",
        "    def __init__(self, dataframe, text_column, label_column):\n",
        "        self.dataframe = dataframe\n",
        "        self.text_column = text_column\n",
        "        self.label_column = label_column\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        text = self.dataframe.iloc[idx][self.text_column]\n",
        "        label = self.dataframe.iloc[idx][self.label_column]\n",
        "\n",
        "        return text, torch.tensor(label, dtype=torch.long)"
      ],
      "metadata": {
        "id": "61KlUA8Nm8q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TextLabelDataset(df_train, \"text_preprocessed\", \"cf_binary\")\n",
        "val_dataset = TextLabelDataset(df_val, \"text_preprocessed\", \"cf_binary\")"
      ],
      "metadata": {
        "id": "OXE24qljm_Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bert_binary_classifier(train_dataset, val_dataset, epochs=10, batch_size=16, learning_rate=3e-6, device=\"cuda\"):\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "    model.to(device)\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_model = None\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, labels = batch\n",
        "            inputs = tokenizer(inputs, padding = \"max_length\", max_length = 512, return_tensors=\"pt\", truncation=True).to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(**inputs).logits\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "        \n",
        "        train_loss /= len(train_loader)\n",
        "        train_accuracy = train_correct / train_total\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        val_preds = []\n",
        "        val_true = []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                inputs, labels = batch\n",
        "                inputs = tokenizer(inputs, padding = \"max_length\", max_length = 512, return_tensors=\"pt\", truncation=True).to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                outputs = model(**inputs).logits\n",
        "                loss = loss_function(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                \n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "                val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
        "                val_true.extend(labels.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_accuracy = val_correct / val_total\n",
        "        val_f1_score = f1_score(val_true, val_preds)\n",
        "        #print(val_preds)\n",
        "        #print(val_true)\n",
        "            \n",
        "        print(f'Epoch: {epoch + 1} '\n",
        "              f'| Train Loss: {train_loss:.3f} '\n",
        "              f'| Train Accuracy: {train_accuracy:.3f} '\n",
        "              f'| Val Loss: {val_loss:.3f} '\n",
        "              f'| Val Accuracy: {val_accuracy:.3f} '\n",
        "              f'| Val F1 Score: {val_f1_score:.3f}')\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model = model.state_dict()\n",
        "\n",
        "    model.load_state_dict(best_model)\n",
        "    return model, best_model"
      ],
      "metadata": {
        "id": "UIUu18UPnBhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model, best_model_state_dict = train_bert_binary_classifier(train_dataset, val_dataset)"
      ],
      "metadata": {
        "id": "WtbB8D1-nEkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load your data (replace with your dataset)\n",
        "# data = pd.read_csv('path_to_your_data.csv')\n",
        "X = df[\"text_preprocessed\"]\n",
        "y = df[\"cf_binary\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Build the SVM pipeline\n",
        "svm_pipeline = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', SVC(kernel='linear', probability=True)),\n",
        "])\n",
        "\n",
        "# Train the SVM classifier\n",
        "svm_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Test the SVM classifier\n",
        "svm_y_pred = svm_pipeline.predict(X_test)\n",
        "svm_y_prob = svm_pipeline.predict_proba(X_test)\n",
        "\n",
        "# Print classification metrics for SVM\n",
        "print(classification_report(y_test, svm_y_pred))\n",
        "print(confusion_matrix(y_test, svm_y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, svm_y_pred))\n",
        "print(\"F1:\", f1_score(y_test, svm_y_pred))\n"
      ],
      "metadata": {
        "id": "NpAtSOwZpq7y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}